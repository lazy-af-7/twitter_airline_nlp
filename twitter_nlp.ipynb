{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0mgkcgYsK8d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "import string\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "dYKfnTXpsdae",
        "outputId": "c336065d-0586-4098-8180-484467e1c7e1"
      },
      "source": [
        "df=pd.read_csv('https://raw.githubusercontent.com/lazy-af-7/twitter_airline_nlp/main/Train.csv')\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>569612379811676161</td>\n",
              "      <td>negative</td>\n",
              "      <td>US Airways</td>\n",
              "      <td>NaN</td>\n",
              "      <td>09202010</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@USAirways US Airlines 699 LA to RDU is holdin...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-22 13:39:08 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mountain Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>570283248301043712</td>\n",
              "      <td>negative</td>\n",
              "      <td>Southwest</td>\n",
              "      <td>NaN</td>\n",
              "      <td>slobotski</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@SouthwestAir went to purchase a flight that I...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 10:04:56 -0800</td>\n",
              "      <td>Midwest + Airplanes</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>569684565838553088</td>\n",
              "      <td>negative</td>\n",
              "      <td>American</td>\n",
              "      <td>NaN</td>\n",
              "      <td>61jr</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@AmericanAir their flights into Buffalo as wel...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-22 18:25:59 -0800</td>\n",
              "      <td>St. Catharines</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>569313126342123520</td>\n",
              "      <td>negative</td>\n",
              "      <td>US Airways</td>\n",
              "      <td>NaN</td>\n",
              "      <td>iZoom23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@USAirways Sitting in a cesspool of germs on t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-21 17:50:01 -0800</td>\n",
              "      <td>New York</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>569723892358467584</td>\n",
              "      <td>negative</td>\n",
              "      <td>United</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ljtypes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@united you advertise the flight and its still...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-22 21:02:15 -0800</td>\n",
              "      <td>H-town</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                user_timezone\n",
              "0           0  ...  Mountain Time (US & Canada)\n",
              "1           1  ...   Central Time (US & Canada)\n",
              "2           2  ...                          NaN\n",
              "3           3  ...   Eastern Time (US & Canada)\n",
              "4           4  ...                          NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3p0obqjstwF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "486cfcb7-0447-4b3c-af42-1bdcd270cf3f"
      },
      "source": [
        "df=df[['airline_sentiment','text']]\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>@USAirways US Airlines 699 LA to RDU is holdin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>@SouthwestAir went to purchase a flight that I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>@AmericanAir their flights into Buffalo as wel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@USAirways Sitting in a cesspool of germs on t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@united you advertise the flight and its still...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                               text\n",
              "0          negative  @USAirways US Airlines 699 LA to RDU is holdin...\n",
              "1          negative  @SouthwestAir went to purchase a flight that I...\n",
              "2          negative  @AmericanAir their flights into Buffalo as wel...\n",
              "3          negative  @USAirways Sitting in a cesspool of germs on t...\n",
              "4          negative  @united you advertise the flight and its still..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdjidFo8uRcH"
      },
      "source": [
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \n",
        "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
        "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
        "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
        "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
        "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
        "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
        "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
        "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
        "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
        "             \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "data=df.copy()\n",
        "def remove_stopwords(data):\n",
        "  data['review without stopwords'] = data['text'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
        "  return data\n",
        "\n",
        "def remove_tags(string):\n",
        "    result = re.sub('<.*?>','',string)\n",
        "    return result\n",
        "    \n",
        "data_without_stopwords = remove_stopwords(data)\n",
        "data_without_stopwords['clean_review']= data_without_stopwords['review without stopwords'].apply(lambda cw : remove_tags(cw))\n",
        "data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf7X9Ka2uZj_"
      },
      "source": [
        "tweet_list = []\n",
        "for i in range(len(data['text'])):\n",
        "  tweet_list.append(data_without_stopwords['clean_review'])\n",
        " \n",
        "sentiment = data_without_stopwords['airline_sentiment']"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjLU_i2i04WW",
        "outputId": "222e29a0-9599-4834-da83-04d7d5a79b1f"
      },
      "source": [
        "print(tweet_list[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        USAirways US Airlines 699 LA RDU holding onto...\n",
            "1        SouthwestAir went purchase flight I began pro...\n",
            "2        AmericanAir flights Buffalo well    You fligh...\n",
            "3        USAirways Sitting cesspool germs ground  PHL ...\n",
            "4        united advertise flight still website still c...\n",
            "                              ...                        \n",
            "7681     USAirways I promise  I can help I will nvr fl...\n",
            "7682    “ USAirways  Reminder  From 2 28  we’ll tweeti...\n",
            "7683     USAirways flight 1898 landed 2 hours ago stil...\n",
            "7684          united alright thank you  Much appreciated \n",
            "7685     united btw   Virgin  JetBlue managed time dep...\n",
            "Name: clean_review, Length: 7686, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCDz0Upc1gMr"
      },
      "source": [
        "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, sentiment)))\n",
        "\n",
        "X_train, X_test,Y_train, Y_test = train_test_split(tweet_list[0], y, test_size=0.2, random_state = 45)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KlQWjjB3dK_",
        "outputId": "98d408a4-5383-4839-f541-9c811c5cfcec"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7157     SouthwestAir thank much completely made thing...\n",
            "5793                           united still waiting reply\n",
            "5853     AmericanAir flt 7a tom  I now rec d notificat...\n",
            "3208     AmericanAir  united wrote back saying  it s c...\n",
            "2974     AmericanAir seats assigned inappropriate chil...\n",
            "                              ...                        \n",
            "3616     USAirways flight 4524 delayed 2 hours deadhea...\n",
            "6012     united flight 4841   3 gate changes top this ...\n",
            "5763                  VirginAmerica save 871 tomorrow AM \n",
            "6558     USAirways   I m Cust Svc line  Your Charlotte...\n",
            "7115                   AmericanAir boarding 2mins YAY    \n",
            "Name: clean_review, Length: 6148, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwDBUyGr29aK"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "words_to_index = tokenizer.word_index"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbBy6H7v3CRq"
      },
      "source": [
        "def read_glove_vector(glove_vec):\n",
        "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    word_to_vec_map = {}\n",
        "    for line in f:\n",
        "      w_line = line.split()\n",
        "      curr_word = w_line[0]\n",
        "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "\n",
        "\n",
        "\n",
        "  return word_to_vec_map"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjGxz3Ja3pVi"
      },
      "source": [
        "word_to_vec_map = read_glove_vector('/content/drive/MyDrive/Twitter NLP/glove.twitter.27B.100d.txt')\n",
        "\n",
        "maxLen = 150"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsQCK6E63wLL"
      },
      "source": [
        "vocab_len = len(words_to_index)\n",
        "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
        "\n",
        "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
        "\n",
        "for word, index in words_to_index.items():\n",
        "  embedding_vector = word_to_vec_map.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    emb_matrix[index, :] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA6HFVeO4AjO"
      },
      "source": [
        "def imdb_rating(input_shape):\n",
        "\n",
        "  X_indices = Input(input_shape)\n",
        "\n",
        "  embeddings = embedding_layer(X_indices)\n",
        "\n",
        "  X = LSTM(128, return_sequences=True)(embeddings)\n",
        "\n",
        "  X = Dropout(0.6)(X)\n",
        "\n",
        "  X = LSTM(128, return_sequences=True)(X)\n",
        "\n",
        "  X = Dropout(0.6)(X)\n",
        "\n",
        "  X = LSTM(128)(X)\n",
        "\n",
        "  X = Dense(1, activation='sigmoid')(X)\n",
        "\n",
        "  model = Model(inputs=X_indices, outputs=X)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnvYfUpE4lXh",
        "outputId": "ce2019bf-9155-4a2f-d2ad-ce7388f69281"
      },
      "source": [
        "\n",
        "model = imdb_rating((maxLen,))\n",
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 150, 100)          932900    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 150, 128)          117248    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 150, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 150, 128)          131584    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 150, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,313,445\n",
            "Trainable params: 380,545\n",
            "Non-trainable params: 932,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJZ0wh1C4DeI"
      },
      "source": [
        "\n",
        "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
        "\n",
        "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpA989W-4HDp",
        "outputId": "73a60c15-7fab-4a00-b398-39e4b21ec22b"
      },
      "source": [
        "adam = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_indices, Y_train, batch_size=64, epochs=8)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "97/97 [==============================] - 97s 945ms/step - loss: 0.4481 - accuracy: 0.8372\n",
            "Epoch 2/8\n",
            "97/97 [==============================] - 97s 1s/step - loss: 0.4488 - accuracy: 0.8358\n",
            "Epoch 3/8\n",
            "97/97 [==============================] - 93s 963ms/step - loss: 0.4471 - accuracy: 0.8366\n",
            "Epoch 4/8\n",
            "97/97 [==============================] - 94s 964ms/step - loss: 0.4479 - accuracy: 0.8355\n",
            "Epoch 5/8\n",
            "97/97 [==============================] - 93s 963ms/step - loss: 0.4444 - accuracy: 0.8386\n",
            "Epoch 6/8\n",
            "97/97 [==============================] - 94s 968ms/step - loss: 0.4342 - accuracy: 0.8447\n",
            "Epoch 7/8\n",
            "97/97 [==============================] - 94s 965ms/step - loss: 0.4515 - accuracy: 0.8332\n",
            "Epoch 8/8\n",
            "97/97 [==============================] - 93s 962ms/step - loss: 0.4431 - accuracy: 0.8390\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f856ffbda50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuWf8tSX4I-d"
      },
      "source": [
        "test=pd.read_csv('https://raw.githubusercontent.com/lazy-af-7/twitter_airline_nlp/main/Train.csv')\n",
        "test=test[['text']]\n",
        "X_test=test['text'].tolist()\n",
        "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')\n",
        "preds = model.predict(X_test_indices)\n",
        "\n",
        "predicted=[]\n",
        "for i in range(len(preds)):\n",
        "  if preds[i] > 0.6:\n",
        "    predicted.append('positive')\n",
        "  elif preds[i] < 0.4:\n",
        "    predicted.append('negative')\n",
        "  else :\n",
        "    predicted.append('neutral')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afMlmJMt7mrl"
      },
      "source": [
        "final=pd.DataFrame()\n",
        "final[\"Id\"]=test.index\n",
        "final['Predicted']=predicted\n",
        "final.to_csv('out.csv',index=False)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK5zRACC9X5Z"
      },
      "source": [
        ""
      ]
    }
  ]
}